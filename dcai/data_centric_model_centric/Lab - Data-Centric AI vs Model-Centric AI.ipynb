{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e5916b2",
   "metadata": {},
   "source": [
    "# Lab: Data-Centric vs Model-Centric approaches\n",
    "\n",
    "This lab gives an introduction to data-centric vs model-centric approaches to machine learning problems, showing how data-centric approaches can outperform purely model-centric approaches.\n",
    "\n",
    "In this lab, we'll build a classifier for product reviews (restricted to the magazine category), like:\n",
    "\n",
    "> Excellent! I look forward to every issue. I had no idea just how much I didn't know.  The letters from the subscribers are educational, too.\n",
    "\n",
    "Label: ⭐️⭐️⭐️⭐️⭐️ (good)\n",
    "\n",
    "> My son waited and waited, it took the 6 weeks to get delivered that they said it would but when it got here he was so dissapointed, it only took him a few minutes to read it.\n",
    "\n",
    "Label: ⭐️ (bad)\n",
    "\n",
    "We'll work with a dataset that has some issues, and we'll see how we can squeeze only so much performance out of the model by being clever about model choice, searching for better hyperparameters, etc. Then, we'll take a look at the data (as any good data scientist should), develop an understanding of the issues, and use simple approaches to improve the data. Finally, we'll see how improving the data can improve results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5874cd",
   "metadata": {},
   "source": [
    "## Installing software\n",
    "\n",
    "For this lab, you'll need to install [scikit-learn](https://scikit-learn.org/) and [pandas](https://pandas.pydata.org/). If you don't have them installed already, you can install them by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a3e0ee93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install scikit-learn pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dbfce6",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "\n",
    "First, let's load the train/test sets and take a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7405df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5a633542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>str_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>As such, I am unable to review it.\\n\\nHowever,...</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>Love this magazine look forward to it every month</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Have gotten this magazine for years.  Really l...</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>I love this magazine, a little of everything; ...</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>Their magazine is more like a virus than a mag...</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  label str_label\n",
       "529  As such, I am unable to review it.\\n\\nHowever,...      0       bad\n",
       "361  Love this magazine look forward to it every month      1      good\n",
       "449  Have gotten this magazine for years.  Really l...      1      good\n",
       "31   I love this magazine, a little of everything; ...      1      good\n",
       "714  Their magazine is more like a virus than a mag...      0       bad"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('reviews_train.csv')\n",
    "test = pd.read_csv('reviews_test.csv')\n",
    "\n",
    "label_mapping = {'bad': 0, 'good': 1}\n",
    "\n",
    "train['str_label'] = train['label']\n",
    "test['str_label'] = test['label']\n",
    "# Convert the label IDs in your DataFrame to integers\n",
    "train['label'] = train['label'].map(label_mapping)\n",
    "test['label'] = test['label'].map(label_mapping)\n",
    "\n",
    "test.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6446a894",
   "metadata": {},
   "source": [
    "# Training a baseline model\n",
    "\n",
    "There are many approaches for training a sequence classification model for text data. In this lab, we're giving you code that mirrors what you find if you look up [how to train a text classifier](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html), where we'll train an SVM on [tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) features (numeric representations of each text field based on word occurrences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "26e13e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "afcb7dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "14a09cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sgd_clf.fit(train['review'], train['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8885717d",
   "metadata": {},
   "source": [
    "## Evaluating model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2850df30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5ccfbaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "60677a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(clf):\n",
    "    pred = clf.predict(test['review'])\n",
    "    acc = metrics.accuracy_score(test['label'], pred)\n",
    "    print(f'Accuracy: {100*acc:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f77729fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.4%\n"
     ]
    }
   ],
   "source": [
    "model_evaluate(sgd_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3880fa",
   "metadata": {},
   "source": [
    "## Trying another model\n",
    "\n",
    "76% accuracy is not great for this binary classification problem. Can you do better with a different model, or by tuning hyperparameters for the SVM trained with SGD?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bdf2c7",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Can you train a more accurate model on the dataset (without changing the dataset)? You might find this [scikit-learn classifier comparison](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html) handy, as well as the [documentation for supervised learning in scikit-learn](https://scikit-learn.org/stable/supervised_learning.html).\n",
    "\n",
    "One idea for a model you could try is a [naive Bayes classifier](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html).\n",
    "\n",
    "You could also try experimenting with different values of the model hyperparameters, perhaps tuning them via a [grid search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). \n",
    "\n",
    "Or you can even try training multiple different models and [ensembling their predictions](https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier), a strategy often used to win prediction competitions like Kaggle.\n",
    "\n",
    "**Advanced:** If you want to be more ambitious, you could try an even fancier model, like training a Transformer neural network. If you go with that, you'll want to fine-tune a pre-trained model. This [guide from HuggingFace](https://huggingface.co/docs/transformers/training) may be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3ca681e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afba8bc648ec4dc6ab4abe162271ab53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6666 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba82131ccd9d4f298006c0d4c1a98eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0d9f0e55fb4c379b28ba957dfb5077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f253026edb4d96aa00627b587ecaa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6390820145606995, 'eval_accuracy': 0.65, 'eval_runtime': 56.1293, 'eval_samples_per_second': 1.782, 'eval_steps_per_second': 0.232, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc0d1fba97547f6a40ef1582db1b767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5722716450691223, 'eval_accuracy': 0.81, 'eval_runtime': 56.5609, 'eval_samples_per_second': 1.768, 'eval_steps_per_second': 0.23, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f39baffb8f48a38761156f8fb80b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5211515426635742, 'eval_accuracy': 0.8, 'eval_runtime': 56.6856, 'eval_samples_per_second': 1.764, 'eval_steps_per_second': 0.229, 'epoch': 3.0}\n",
      "{'train_runtime': 796.6219, 'train_samples_per_second': 0.377, 'train_steps_per_second': 0.049, 'train_loss': 0.6394604903001052, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# evaluate your model and see if it does better\n",
    "# than the ones we provided\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "def train_hugging_face_model(train_df, test_df):\n",
    "    train_dataset = Dataset.from_pandas(train_df)\n",
    "    test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"review\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "    tokenized_train_datasets = train_dataset.map(tokenize_function, batched=True)\n",
    "    tokenized_test_datasets = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n",
    "    training_args = TrainingArguments(output_dir=\"test_trainer\")\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "    use_large = False\n",
    "    training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train_datasets if use_large else small_train_dataset,\n",
    "        eval_dataset=tokenized_test_datasets if use_large else small_test_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "train_hugging_face_model(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "52dcfe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tokenized_datasets[1]\n",
    "# small_train_dataset = tokenized_train_datasets.shuffle(seed=42).select(range(100))\n",
    "# small_test_dataset = tokenized_test_datasets.shuffle(seed=42).select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592583d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a530ee43",
   "metadata": {},
   "source": [
    "## Taking a closer look at the training data\n",
    "\n",
    "Let's actually take a look at some of the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ab34483c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>str_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Based on all the negative comments about Taste...</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I still have not received this.  Obviously I c...</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;/tr&gt;The magazine is not worth the cost of sub...</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This magazine is basically ads. Kindve worthle...</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The only thing I've recieved, so far, is the b...</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label str_label\n",
       "0  Based on all the negative comments about Taste...      1      good\n",
       "1  I still have not received this.  Obviously I c...      0       bad\n",
       "2  </tr>The magazine is not worth the cost of sub...      1      good\n",
       "3  This magazine is basically ads. Kindve worthle...      0       bad\n",
       "4  The only thing I've recieved, so far, is the b...      0       bad"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3c84e2",
   "metadata": {},
   "source": [
    "Zooming in on one particular data point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6ebf3a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'review': \"Based on all the negative comments about Taste of Home, I will not subscribeto the magazine. In the past it was a great read.\\nSorry it, too, has gone the 'way of the wind'.<br>o-p28pass4 </br>\", 'label': 1, 'str_label': 'good'}\n"
     ]
    }
   ],
   "source": [
    "print(train.iloc[0].to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b839b33f",
   "metadata": {},
   "source": [
    "This data point is labeled \"good\", but it's clearly a negative review. Also, it looks like there's some funny HTML stuff at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e608bbc6",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Take a look at some more examples in the dataset. Do you notice any patterns with bad data points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "82e43ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'review': {156: '</ul>Bad experience. These magazines are almost like 85% adds and 15% real info. I wish I could cancel this. By the way, they enrolled me for another year. Just plain bad.</li>', 6052: \"This is by far one my favorite magazines. There is nothing bad I could ever write about it. It's an awesome magazine. Get it.\", 5895: 'I really shouldn\\'t rate this bad. its a good magazine just tied to amazon\\'s lack of support for pc. Kindle for pc will not support this magazine.<p class=\"foot\">', 167: 'Awful access and bad customer service<ul class=\"blockList\">', 3527: 'DataTables.</p>Do not want, did not order, Please cancel per our phone call. Bad bad bad.', 1648: 'Instructions on how to access the electronic version must be provided. An access link would be best.<td>$1,200,bad00</td>', 4856: 'Never get the bag, as magazine not to bad<li>setAttributeNS', 1212: '</li>Fine Magazine, too bad I get two every month.2      <BR>', 6095: \"<li>Unless your looking for a $100,bad00.00 toon don't waste your money. All articles seem to be copy paste from manufacture.\", 5985: \"<li>addFor a magazine about active healthy life it's full of ads for bad foods. I cancelled the subscription.\"}, 'label': {156: 1, 6052: 1, 5895: 1, 167: 1, 3527: 1, 1648: 1, 4856: 1, 1212: 1, 6095: 1, 5985: 1}, 'str_label': {156: 'good', 6052: 'good', 5895: 'good', 167: 'good', 3527: 'good', 1648: 'good', 4856: 'good', 1212: 'good', 6095: 'good', 5985: 'good'}}\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "mask = (train['review'].str.contains('bad|don\\'t recommend')) & (train['label'] == 1)\n",
    "filtered_df = train.loc[mask]\n",
    "random_rows = filtered_df.sample(n=10)\n",
    "print(random_rows.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae38448f",
   "metadata": {},
   "source": [
    "## Issues in the data\n",
    "\n",
    "It looks like there's some funny HTML tags in our dataset, and those datapoints have nonsense labels. Maybe this dataset was collected by scraping the internet, and the HTML wasn't quite parsed correctly in all cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664845e4",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "To address this, a simple approach we might try is to throw out the bad data points, and train our model on only the \"clean\" data.\n",
    "\n",
    "Come up with a simple heuristic to identify data points containing HTML, and filter out the bad data points to create a cleaned training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5990cdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_bad_data(review: str) -> bool:\n",
    "    # YOUR CODE HERE\n",
    "    special_chars = ['<', '/', '>']\n",
    "    return all(char in review for char in special_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092849c1",
   "metadata": {},
   "source": [
    "## Creating the cleaned training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e9c7671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = train[~train['review'].map(is_bad_data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1740bf3b",
   "metadata": {},
   "source": [
    "## Evaluating a model trained on the clean training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0e83abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e5e3c7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf_clean = clone(sgd_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6f72b0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sgd_clf_clean.fit(train_clean['review'], train_clean['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775ebff4",
   "metadata": {},
   "source": [
    "This model should do significantly better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "80b78100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.0%\n"
     ]
    }
   ],
   "source": [
    "model_evaluate(sgd_clf_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "831d6aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34116924e5c74982939d0990fbc80e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4827 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06970aa7f0a34c198f1357b933e84ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1381f8d79c754746a88d30b0ea6ee091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64133c7649f45898eb6dbcd23a0b6a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6390820145606995, 'eval_accuracy': 0.65, 'eval_runtime': 55.2556, 'eval_samples_per_second': 1.81, 'eval_steps_per_second': 0.235, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1459da89345b4c35b7ab8e286aef47d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_hugging_face_model(train_clean, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3bb40f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
